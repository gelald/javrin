# 系统调用函数

## recvfrom

Linux系统提供给用户用于接收网络IO的系统接口。从套接字上接收一个消息

如果此系统调用返回值<0，并且 errno为EWOULDBLOCK或EAGAIN（套接字已标记为非阻塞，而接收操作被阻塞或者接收超时 ）时，连接正常，**阻塞**接收数据（这很关键，前4种IO模型都设计此系统调用）

## select

系统调用允许程序同时在多个底层文件描述符上，等待输入的到达或输出的完成。以**数组**形式存储文件描述符，64位机器默认**2048**个。当有数据准备好时，无法感知具体是哪个流OK了，所以需要一个一个的遍历，函数的时间复杂度为**O(n)**

### select函数的缺陷

1. select调用需要传入文件描述符数组，也就是说需要拷贝这份数组到内核缓冲区，在高并发的场景下这种拷贝操作会消耗大量资源
2. select调用在内核层仍然是通过遍历的方式检查文件描述符的就绪状态的这个过程是同步的，只不过没有系统调用切换上下文的开销
3. select调用仅仅返回的是可读文件描述符的个数，具体哪个可读还需要用户线程进行遍历

## poll

以**链表**形式存储文件描述符，与select函数主要的区别为取消了1024个文件描述符的限制，函数的时间复杂度也为**O(n)**

## epoll

基于事件驱动的，如果某个流准备好了，会以事件通知，知道具体是哪个流，因此不需要遍历，函数的时间复杂度为**O(1)**

### epoll解决select函数缺陷的方式

1. 内核中保存一份文件描述符集合，无需用户层每次都重新传入，只需告诉内核修改的部分即可
2. 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步IO事件通知
3. 内核仅会将有IO事件的文件描述符返回给用户层，用户层拿到后无需做额外的遍历

## sigaction

用于设置对信号的处理方式，也可检验对某信号的预设处理方式。Linux使用**SIGIO信号**来实现IO异步通知机制



# IO模型

不管是网络IO还是磁盘IO，对于读操作，都需要等待网络的某个数据分组到达后/准备好，**将数据拷贝到内核空间的缓冲区中，再从内核空间拷贝到用户空间的缓冲区**

## 阻塞IO模型

> 此时我已饥渴难耐，全程**盯着**后厨，等待着一分一秒，终于全家桶做好了，在此期间虽然什么事也没干，但是最后能吃到全家桶，我很幸福。此处需要一个清新的脑回路，我就是程序，我想要全家桶，于是**发起了系统调用**，而后厨加工的过程就是在做**数据准备和拷贝**工作。全家桶最终到手，数据终于从内核空间拷贝到了用户空间。

```java
listenfd = socket();   			// 打开一个网络通信端口
bind(listenfd);        			// 绑定
listen(listenfd);      			// 监听
while(1) {
  connfd = accept(listenfd);  	// 阻塞建立连接
  int n = read(connfd, buf);  	// 阻塞读数据
  doSomeThing(buf);  			// 利用读到的数据完成业务操作
  close(connfd);     			// 关闭连接，循环等待下一个连接
}
```

![](https://mmbiz.qpic.cn/mmbiz_gif/GLeh42uInXTyY80RSpUTLjIMiaGGicv9zArJDictJLnnRWwXriaXkgJFXnUsibFTlxjqSaBicqpeH4NhXBCqWuFgc7VQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

总体来看，会有两个地方发生阻塞

1. accept方法，这里需要完成Http三次握手操作，属于网络层，无法从代码层面优化
2. read方法，把read方法细节展开看，会有两个阶段发生阻塞
   1. 数据从网卡拷贝到内核缓冲区，完成后文件描述符的状态被修改为读已就绪
   2. 数据从内核拷贝到用户缓冲区，完成后返回到达的字节数

![图片](https://mmbiz.qpic.cn/mmbiz_gif/GLeh42uInXTyY80RSpUTLjIMiaGGicv9zADM8nrhNkEtFpSpLjGicOemZ5mt7orYF8vFC7g83lPVDeSbnlgKl7XaA/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

整体流程如下：

![](https://gitee.com/ngwingbun/picgo-image/raw/master/images/20210817095814.png)

阻塞IO的执行过程是进程进行系统调用，**等待内核**将数据准备好并复制到用户态缓冲区后，进程**放弃使用CPU**并**一直阻塞**在此，直到数据准备好

如果这个连接的客户端一直不发数据，那么服务端线程将会**一直阻塞在 read 函数上不返回，也无法接受其他客户端连接**

## 非阻塞IO模型

> 此时我**每隔5分钟**询问全家桶好了没，在数次盘问后，终于出炉了。在每一次盘问之前，对于程序来说是**非阻塞的**，**占用CPU资源**，可以做其他事情。

操作系统提供的recvfrom函数可以实现非阻塞的效果。调用recvfrom前，把文件描述符设置为非阻塞（errno设置为EWOULDBLOCK），每次应用程序需要**询问内核**是否有数据准备好。当数据还没拷贝到用户缓冲区前都返回-1，用户线程需要进入下一轮的轮询；当数据在内核缓冲区准备好拷贝到用户缓冲区时，recvfrom函数会进入阻塞阶段，然后开始拷贝数据到用户缓冲区，完成后函数会返回到达的字节数，并开始处理业务

![图片](https://mmbiz.qpic.cn/mmbiz_gif/GLeh42uInXTyY80RSpUTLjIMiaGGicv9zAT6rHhibbzK5rXiarLuJU0P4MGrHNl35vVCV4JdS4FeejOkl8bBGz9nVQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

整体流程图如下：

![](https://gitee.com/ngwingbun/picgo-image/raw/master/images/20210817154602.png)

非阻塞IO的执行过程经历两个阶段

- **等待数据阶段是非阻塞的**，当数据还未到网卡，或者数据到达网卡了但是还没拷贝到内核缓冲区之前，用户线程需要不停地去**轮询内核**数据的就绪状态
- **数据复制阶段是阻塞的**，需要等待数据从内核缓冲区拷贝到用户缓冲区，才能返回

## IO多路复用模型

> 排了很长的队，终于轮到我支付后，拿到了一张小票，上面有**号次**。当全家桶出炉后，会喊相应的号次来取。KFC营业员小姐姐打小票出号次的动作相当于操作系统**多开了个线程**，专门接收客户端的连接。我只关注叫到的是不是我的号，因此程序还需在服务端**注册我想监听的事件**类型。

当服务端和多个客户端建立连接时，如果为每一个客户端创建一个线程，那么服务端的线程资源很容易就被消耗完

我们可以把建立连接的客户端的文件描述符都存放到一个数组里面，通过系统调用函数select，把一个文件描述符的数组发给操作系统，让操作系统去完成遍历并确定哪个文件描述符是可以进行读写的，然后用户线程根据结果进行处理

### 服务端代码

线程A

```
while(1) {
  // 不断接受客户端连接，并把 socket 文件描述符放到一个 list 里
  connfd = accept(listenfd);
  fcntl(connfd, F_SETFL, O_NONBLOCK);
  fdlist.add(connfd);
}
```

线程B

```
while(1) {
  // 把一堆文件描述符 list 传给 select 函数
  // 有已就绪的文件描述符就返回，nready 表示有多少个就绪的
  nready = select(fdlist);
  // 用户层依然要遍历，只不过少了很多无效的系统调用
  for(fd <-- fdlist) {
    if(fd != -1) {
      // 只读已就绪的文件描述符
      read(fd, buf);
      // 总共只有 nready 个已就绪描述符，不用过多遍历
      if(--nready == 0) break;
    }
  }
}
```

![图片](https://mmbiz.qpic.cn/mmbiz_gif/GLeh42uInXTyY80RSpUTLjIMiaGGicv9zAicgy5qFYcyoWPAV31k82icRe6I4Lya2F9qWcBlhHv3kzpgt9yjD7Hnpw/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)



整体流程如下：

![](https://gitee.com/ngwingbun/picgo-image/raw/master/images/20210817160011.png)

- 对于用户层来说，一般**感受不到阻塞**，因为请求来了，可以用放到线程池里执行

- 但对于执行select的内核层而言，是**阻塞**的，需要阻塞地**等待某个套接字变为可读**。
- 做到了一个线程处理多个客户端连接（文件描述符），又减少了系统调用的开销（多个文件描述符只有一次 select 的系统调用 + n 次就绪状态的文件描述符的 recvfrom 系统调用）

- IO多路复用其实是阻塞在select，poll，epoll这类系统调用上的，**复用的是执行select，poll，epoll的线程**

## 信号驱动IO模型

> 跑KFC嫌麻烦，刚好有个会员，直接点份外卖，美滋滋。当外卖送达时，会收到取餐电话（信号）。在收到取餐电话之前，我可以愉快地吃鸡或者学习。

![](https://gitee.com/ngwingbun/picgo-image/raw/master/images/%E4%BF%A1%E5%8F%B7%E9%A9%B1%E5%8A%A8IO%E6%A8%A1%E5%9E%8B.png)

信号驱动IO模型执行分为两个阶段：

- **数据准备阶段是不阻塞的**，当数据准备完成之后，会主动地通知用户进程数据已经准备完成，对用户线程做一个回调
- **数据拷贝阶段是阻塞的**，等待数据拷贝

与非阻塞IO模型的区别在于第一阶段，非阻塞IO模型是轮询结果，信号驱动IO模型是等待信号

## 异步IO模型

> 此时科技的发展已经超乎想象了，外卖机器人将全家桶自动送达并**转换成营养**快速注入我的体内，同时还能得到口感的满足。注入结束后，机器人会提醒我注入完毕。在这个期间我可以放心大胆的玩，甚至注射的时候也**不需要停下来**！

![](https://gitee.com/ngwingbun/picgo-image/raw/master/images/%E5%BC%82%E6%AD%A5IO%E6%A8%A1%E5%9E%8B.png)

用户进程发起系统调用后，立刻就可以开始去做其他的事情，然后直到I/O**数据准备好并复制完成后**，内核会给用户进程**发送通知**，告诉用户进程操作**已经完成**了。

特点：

- 异步IO执行的**两个阶段都不会阻塞**读写操作，由内核完成
- 完成后内核将数据放到指定的缓冲区，**通知**应用程序来取

## 总结

- 从效率上看：阻塞IO<非阻塞IO<多路复用IO<信号驱动IO<异步IO
- 从同步/异步看：只有异步IO模型是异步的，其他均为同步

### IO模型的发展经历

1. 一切的开始都是源于操作系统给我们提供的recvfrom这个阻塞的函数，我们称之为**阻塞IO**
2. 为了减少阻塞带来的等待时间，程序员在用户态通过多线程来防止主线程卡死
   - 主线程接收客户端
   - 新建子线程完成阻塞的recvfrom函数调用
3. 后来操作系统发现这个需求比较大，于是在操作系统层面提供了非阻塞的recvfrom函数，通过修改文件描述符的errorno，这样就可以在一个线程内完成多个文件描述符的读取，我们称之为**非阻塞IO**
4. 但是多个文件描述符的读取就需要遍历，当高并发场景下，用户态需要遍历的文件描述符变得多起来了，相当于在一个while循环内进行了更多的系统调用，此时性能大打折扣
5. 后来操作系统又发现这个场景需求量较大，于是又在操作系统层面提供了遍历文件描述符的函数，用户态可以直接从内核态拿到可读写的文件描述符，我们称之为**IO多路复用**
6. IO多路复用有三个函数，最开始是select，然后又发明了poll解决了select对文件描述符的限制，接着又发明了epoll解决了select三个不足

**所以，IO 模型的演进，其实就是时代的变化，倒逼着操作系统将更多的功能加到自己的内核而已**

在内核态完成操作肯定比在用户态完成操作效率高



# BIO - 同步阻塞

## 实现过程

1. 在服务端启动一个ServerSocket来**监听网络请求**
2. 客户端启动Socket发起网络请求
3. 默认情况下ServerSocket会**建立一个线程**来处理此请求，如果服务端没有线程可用，客户端则会**阻塞等待**或遭到**拒绝**，**并发效率比较低**

## 实现原理

**一个连接一个线程**，若有客户端有连接请求服务端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的**线程开销**。可以通过线程池机制改善

## 适用场景

连接数目比较小且固定的架构，对服务器资源要求高，并发局限于应用中

# NIO - 同步非阻塞

## 实现原理

**一个请求一个通道**，即客户端发送的连接请求都会**注册到多路复用器**上，多路复用器轮询到连接**有 I/O 请求时才启动**一个线程进行处

## 适用场景

连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中

## 重要角色

### 缓冲区Buffer

所有数据都是用**缓冲区（用户空间缓冲区）处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，也是写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。缓冲区实际上是一个数组，并提供了对数据的结构化访问**以及**维护读写位置**等信息

#### 写操作

1. clear()
2. put() -> 写操作
3. flip() -> 重置游标
4. SocketChannel.write(buffer) -> 将缓存数据发送到网络的另一端
5. clear()

读操作

1. clear()
2. SocketChannel.read(buffer) -> 从网络中读取数据
3. buffer.flip()
4. buffer.get() -> 读取数据
5. buffer.clear()

### 通道Channel

nio中对数据的读取和写入要通过Channel，它就像**水管一样**，是一个通道。通道不同于流的地方就是通道是**双向**的，可以用于读、写和同时读写操作。

### 多路复用器Selector

用于注册通道。客户端发送的连接请求都会注册到多路复用器上，**多路复用器轮询到连接有I/O请求时才启动一个线程进行处理**

# AIO - 异步非阻塞

## 实现原理

进行读写操作时，只需直接调用api的read或write方法即可。**一个有效请求对应一个线程**，客户端的IO请求都是**操作系统先完成了再通知服务器**应用去启动线程进行处理

## 适用场景

连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作