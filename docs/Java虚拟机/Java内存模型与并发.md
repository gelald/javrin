# Java 内存模型与并发

> 这一节我们结合 Java 内存模型来理解并发编程中的一些经典问题，为后续学习并发编程做铺垫

## 基础

### 并发编程模型的分类

在处理并发编程时，我们需要处理两个关键的问题

- 线程之间如何进行通信。线程之间通过哪种方式来进行交换信息
- 线程之间如何进行同步。用于控制不同线程之间操作发生相对顺序的机制

并发编程中常见有两种模型，分别用不同的方式解决了上述两个关键问题：

- **共享内存**的并发编程模型
  - 通信：线程之间共享程序的公共状态，线程之间通过「读-写」公共状态来隐式进行通信
  - 同步：开发人员必须**显式地控制**某个方法或某段代码需要在线程之间互斥地执行

- **消息传递**的并发编程模型
  - 通信：线程之间通过发送消息来显式进行通信
  - 同步：消息发送一定位于消息接收之前，这里存在了一个隐式的同步控制

**Java 中的并发编程模型使用的是共享内存模型**



### Java 内存模型

回顾一下 Java 内存模型，JMM 定义了主内存和线程之间的抽象关系：所有的共享变量（实例域、静态域、数组）都存放在主内存中，所有线程都共享这一部分的数据；线程读写共享变量时需要需要在自己的工作内存中创建副本，修改完成后需要把副本数据更新到主内存中。

![](https://wingbun-notes-image.oss-cn-guangzhou.aliyuncs.com/images/20220416221924.png)

从上图看，假设线程A需要与线程B进行通信的话，需要经历以下两个步骤

- 线程A把工作内存中更新后的共享变量更新到主内存中
- 线程B从主内存中读取线程A更新后的变量

可以看到整个通信过程中，主内存是一个核心的角色，**JMM 通过控制主内存和各线程工作内存的交互，来提供内存可见性的保证**



## 重排序

### 概念

在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序

重排序会分为以下三类：

- （编译器）编译器优化的重排序。在不影响单线程程序语意的前提下，可以重新安排语句的执行顺序
- （处理器）指令级并行的重排序。现代处理器采用了指令级并行技术将多条指令重叠执行。如果不存在数据的依赖性，处理器可以改变语句对应的机器指令的执行顺序
- （处理器）内存系统的重排序。由于处理器使用缓存和「读-写」缓存区，这使得加载和存储操作看上去可能是乱序执行

三种重排序都可能会导致多线程程序出现内存可见性的问题，JMM 为了确保在不同的编译器和不同的处理器平台提供一致的内存可见性的保证，提供了禁止特定类型的编译器重排序和处理器重排序。

其中对于处理器重排序，JMM 处理器重排序会 Java 编译器在生成指令序列时，插入特定的**内存屏障**，以禁止特定类型的处理器重排序



### 处理器重排序

现代的处理器一般都会使用写缓冲区来临时保存向主内存写入的数据，可以保证指令流水线地执行，避免停顿等待写入而产生的延迟。同时批处理刷新主内存和合并多次的对同一内存地址的写入操作，也可以减少对内存总线的占用。

但是每个处理器上的写缓冲区，仅仅对它所在的处理器可见。所以处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！

---

用一个案例说明

```java
// a、b的初始值是0

// Thread A
a = 1;
x = b;

// Thread B
b = 2;
y = a;
```

假设线程 A 和线程 B 按程序的顺序并行执行内存访问，**最终却可能得到 x = y = 0 的结果**

> 线程A、B先把变量a、b修改后写入到自己的工作内存中，然后再从主内存中读取x、y的值，最后再把工作内存中a、b的副本更新到主内存中，导致x、y读取到的值是a、b的更新前的值：0

**从内存的角度看线程A的过程是：先读取b的值，再更新a的值**，线程A的内存操作顺序被重排序了！

这是由于写缓冲区的动作只对自己的处理器可见，这会导致处理器执行内存操作和实际的内存操作顺序不一致，因此**现代的处理器都允许对「写-读」操作做重排序**



### 内存屏障类型

| 屏障类型          | 指令                                 | 说明                                                         |
| ----------------- | ------------------------------------ | ------------------------------------------------------------ |
| LoadLoad屏障      | Load1;<br />LoadLoad;<br />Load2     | 在Load2要读取的数据被访问前，<br />保证Load1要读取的数据被读取完毕 |
| StoreStore屏障    | Store1;<br />StoreStore;<br />Store2 | 在Store2写入前，<br />保证Store1的写入操作对其他处理器可见   |
| LoadStore屏障     | Load1;<br />LoadStore;<br />Store2   | 在Store写入前，<br />保证Load1要读取的数据被读取完毕         |
| **StoreLoad屏障** | Store1;<br />StoreLoad;<br />Load2   | 在Load2要读取的数据被访问前，<br />保证Store1写入完毕        |

其中重点提一下 「StoreLoad屏障」，它同时**具备其他三个屏障的功能**，同时也是**开销最大的屏障**，因为要求在当前处理器要把缓冲区的所有数据刷到主内存中



### happens-before

#### 概念

「happens-before」这个概念用于阐述操作之间的内存可见性。如果一个操作执行的结果要对另一个操作可见，那么这两个操作之间存在 `happens-before` 关系