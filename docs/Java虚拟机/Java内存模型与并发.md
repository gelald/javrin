# Java 内存模型与并发

> 这一节我们结合 Java 内存模型来理解并发编程中的一些经典问题，为后续学习并发编程做铺垫

## 基础

### 并发编程模型的分类

在处理并发编程时，我们需要处理两个关键的问题

- 线程之间如何进行通信。线程之间通过哪种方式来进行交换信息
- 线程之间如何进行同步。用于控制不同线程之间操作发生相对顺序的机制

并发编程中常见有两种模型，分别用不同的方式解决了上述两个关键问题：

- **共享内存**的并发编程模型
  - 通信：线程之间共享程序的公共状态，线程之间通过「读-写」公共状态来隐式进行通信
  - 同步：开发人员必须**显式地控制**某个方法或某段代码需要在线程之间互斥地执行

- **消息传递**的并发编程模型
  - 通信：线程之间通过发送消息来显式进行通信
  - 同步：消息发送一定位于消息接收之前，这里存在了一个隐式的同步控制

**Java 中的并发编程模型使用的是共享内存模型**



### Java 内存模型

回顾一下 Java 内存模型，JMM 定义了主内存和线程之间的抽象关系：所有的共享变量（实例域、静态域、数组）都存放在主内存中，所有线程都共享这一部分的数据；线程读写共享变量时需要需要在自己的工作内存中创建副本，修改完成后需要把副本数据更新到主内存中。

![](https://wingbun-notes-image.oss-cn-guangzhou.aliyuncs.com/images/20220416221924.png)

从上图看，假设线程A需要与线程B进行通信的话，需要经历以下两个步骤

- 线程A把工作内存中更新后的共享变量更新到主内存中
- 线程B从主内存中读取线程A更新后的变量

可以看到整个通信过程中，主内存是一个核心的角色，**JMM 通过控制主内存和各线程工作内存的交互，来提供内存可见性的保证**



## 重排序

### 概念

在执行程序时**为了提高性能**，编译器和处理器常常会对指令做重排序

重排序会分为以下三类：

- （编译器）编译器优化的重排序。**在不影响单线程程序语意的前提下**，可以重新安排语句的执行顺序
- （处理器）指令级并行的重排序。现代处理器采用了指令级并行技术将多条指令重叠执行。如果不存在数据的依赖性，处理器可以改变语句对应的机器指令的执行顺序
- （处理器）内存系统的重排序。由于处理器使用缓存和「读-写」缓存区，这使得加载和存储操作看上去可能是乱序执行



### 重排序可能引发的问题

用单例模式引入

```java
public class Singleton {
	private static Singleton singleton;
	private Singleton(){}
	public static Singleton getInstance(){
        // 检查1
		if(singleton==null){
			synchronized(Singleton.class){
                // 检查2
				if(singleton==null){
					singleton = new Singleton();
				}
			}
		}
		return singleton;
	}
}
```

上述代码中，在多线程环境下 `singleton = new Singleton();` 这一句可能会发生指令重排序

这一句的执行顺序为

1. 分配内存
2. 初始化
3. 把对象指向内存空间

经过重排序后，执行顺序会变成

1. 分配内存
2. 把对象指向内存空间
3. 初始化

在并发环境下，一个线程可能会得到一个还没完成初始化的单例对象，导致在后续使用中得到的值为空

> 当把对象指向内存空间后，线程在检查1时就不进入条件了

而解决这种问题有两种解决方案：**内存屏障**（禁止指令重排序）、**happen-before**（指令重排序必须按照一定的规则）



### happens-before

#### 概念

「happens-before」这个概念用于阐述操作之间的内存可见性。如果一个操作执行的**结果**要对另一个操作**可见**，那么这两个操作之间存在 `happens-before` 关系，那么**不允许进行重排序**



### 内存屏障类型

| 屏障类型          | 指令                                 | 说明                                                         |
| ----------------- | ------------------------------------ | ------------------------------------------------------------ |
| LoadLoad屏障      | Load1;<br />LoadLoad;<br />Load2     | 在Load2要读取的数据被访问前，<br />保证Load1要读取的数据被读取完毕 |
| StoreStore屏障    | Store1;<br />StoreStore;<br />Store2 | 在Store2写入前，<br />保证Store1的写入操作对其他处理器可见   |
| LoadStore屏障     | Load1;<br />LoadStore;<br />Store2   | 在Store写入前，<br />保证Load1要读取的数据被读取完毕         |
| **StoreLoad屏障** | Store1;<br />StoreLoad;<br />Load2   | 在Load2要读取的数据被访问前，<br />保证Store1写入完毕        |

其中重点提一下 「StoreLoad屏障」，它同时**具备其他三个屏障的功能**，同时也是**开销最大的屏障**，因为要求在当前处理器要把缓冲区的所有数据刷到主内存中


